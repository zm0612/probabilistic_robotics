# 第 2 章  递归状态估计

## 2.2 概率的概念

**一维概率正态分布可以使用高斯函数表示：**
$$
p(x) = (2 \pi \sigma^{2})^{-\frac{1}{2}} \exp^{-\frac{1}{2}\frac{(x-\mu)^2}{\sigma^{2}}}  \tag 1
$$
> $\mu$：均值，$\sigma$：方差

**高维概率密度函数：**
$$
p(x) = \det(2 \pi \Sigma)^{-\frac{1}{2}} \exp^{-\frac{1}{2}(x-\mu)^T \Sigma^{-1} (x-\mu)} \tag 2
$$
> $\mu$：均值向量，$\Sigma$：协方差矩阵

**联合分布**
$$
p(x, y) = p(X=x, Y=y) \tag 3
$$
如果，$x,y$相互独立，则
$$
p(x, y) = p(x)p(y) \tag 4
$$
**条件概率**
$$
p(x|y) = \frac{p(x, y)}{p(y)} \tag 5
$$

**全概率公式**
离散情况
$$
p(x) = \sum_y p(x|y)p(y) \tag 6
$$


连续情况
$$
p(x) = \int p(x|y)p(y)dy \tag 7
$$


**贝叶斯准则**
离散
$$
p(x|y) = \frac{p(y|x) p(x)}{p(y)} = \frac{p(y|x) p(x)}{\sum_{x'}p(y|x') p(x')} \tag 8
$$
连续
$$
p(x|y) = \frac{p(y|x) p(x)}{p(y)} = \frac{p(y|x) p(x)}{\int p(y|x') p(x') dx'} \tag 9
$$

> 如果$x$是一个希望由$y$推测出来的数值，则概率$p(x)$称为先验概率分布。$y$称为数据，来自于传感器的测量值。分布$p(x)$总结了综合数据$y$之前已经有的关于$x$的信息。概率$p(x|y)$称为在$X$上的后验概率分布。$p(y|x)$称为生成模型。

贝叶斯公式推广：
$$
p(x|y,z) = \frac{p(y|x,z) p(x|z)}{p(y|z)} \tag {10}
$$
**条件独立**

如果随机变量$x, y$相互独立，则以$z$为条件的联合概率定律：
$$
p(x,y|z) = p(x|z)p(y|z) \tag {11}
$$
可以很容易推广：
$$
p(x|z) = p(x|z, y) \\
p(y|z) = p(y | z, x) \tag {12}
$$

> 但是不同从条件独立说两个变量绝对独立，也就是不能通过等式(11)得出$x,y$绝对独立。
>
> 反过来也不一定成立，绝对独立也不意味着就条件独立。

**期望**

离散
$$
E[X] = \sum_x x p(x) \tag{13}
$$
连续
$$
E[X] = \int x p(x)dx \tag{14}
$$
**方差**
$$
Cov[X] = E[X-E[X]]^2 = E[X^2] - E[X]^2  \tag{15}
$$
**熵**

概率分布的熵可以由下式给出：
$$
H_p(x) = E[-\log_2p(x)] \tag{16}
$$
可导出：
$$
H_p(x) = -\sum_xp(x)\log_2p(x) \\
H_p(x) = -\int p(x)\log_2p(x) \tag{17}
$$

## 2.3 机器人环境交互

**状态**

环境特征以状态$x_t$来表征。典型的状态变量有：机器人位姿、机器人执行机构配置、机器人速度和角速度、环境中物体的位置和特征也是状态变量、移动的物体和人的位置和速度、影响机器人运行的其他状态变量。

如果一个状态$x_t$可以很好的预测未来，则称其为**完整的**。一个也许不是很严谨的理解，未来的状态只会受到$x_t$的影响，没有出$x_t$之外的状态变量可以先于$x_t$影响未来状态的随机变化。满足这些条件的暂态过程通常称为马尔科夫链。在实际条件下，不可能找到这样状态量，因为影响机器人状态的因素非常多，很难穷举。

**环境交互**

- 环境传感器测量；
- 控制动作改变世界的状态；
- 环境测量数据提供了环境的暂态信息；
- 控制数据携带环境中关于状态改变的信息；

**生成法则**

表征状态演变的概率法则：
$$
p(x_t|x_{0:t-1}, z_{1:t-1}, u_{1:t}) \tag{18}
$$
实际上，仅控制量$u_t$关心是否知道状态$x_{t-1}$，因为它需要在此基础之上执行控制。所以这个见解可以由下式表达：
$$
p(z_t|x_{0:t-1}, z_{1:t-1}, u_{1:t}) = p(x_t | x_{t-1}, u_t) \tag{19}
$$
如果$x_t$是**完整的**，那么就会有如下重要条件独立：
$$
p(z_t|x_{0:t-1}, z_{1:t-1}, u_{1:t}) = p(x_t | x_{t-1}, u_t) = p(z_t|x_t) \tag{20}
$$
**主要原因是：如果状态$x_t$是完整的，则任何其他变量的信息，如过去的测量、控制、抑或过去的状态，都和$x_t$无关。**

概率$p(x_t|x_{t-1}, u_t)$是状态转移概率。它指出环境状态作为机器人控制$u_t$的函数是如何随着时间变化。

概率$p(z_t|x_t)$叫做测量概率。测量概率制定概率法则，根据该法则测量$z$由环境状态$x$产生。将测量认为是状态的有噪声预测是恰当的。

**隐马尔可夫模型或者动态贝叶斯网络**表示的是，时刻$t$的状态随机的依赖$t-1$时刻的状态和控制$u_t$。测量$z_t$随机的依赖时刻$t$的状态。

**置信分布**

置信度反映了机器人有关环境状态的内部信息。概率机器人通过条件概率分布表示置信度。置信度其实就是状态的后验概率，用bel($x_t$)表示。
$$
bel(x_t) = p(x_t|z_{1:t}, u_{1:t}) \tag{21}
$$
 式子(21)表示$t$时刻的后验以过去所有的测量$z_{i: t}$和过去所有的控制$u_{1: t}$为条件。

有时候，会先排除式子(21)中的$z_t$，然后计算状态$x_t$。此时，可以得到后验：
$$
\overline{bel}(x_t) = p(x_t|z_{1:t}, u_{1:t}) \tag{22}
$$
式子(22)所表示的概率称为预测。由$\overline{bel}(x_t)$计算$bel(x)$称为修正或者测量更新。

## 2.4 贝叶斯滤波

由贝叶斯公式，得：
$$
p(x_t|z_{1:t}, u_{1:t}) = \frac{p(z_t| x_t, z_{1:t-1},u_{1:t}) p(x_t|z_{1:t-1}, u_{1:t})}{p(z_t|z_{1:t-1}, u_{1:t})}  \\
= \eta p(z_t| x_t, z_{1:t-1},u_{1:t}) p(x_t|z_{1:t-1}, u_{1:t})
\tag{23}
$$
根据状态是完整的这一假设，可以得到：
$$
p(z_t| x_t, z_{1:t-1},u_{1:t})  = p(z_t| x_t) \tag{24}
$$
将式子(23)简化：
$$
p(x_t|z_{1:t}, u_{1:t}) = \eta p(z_t| x_t) p(x_t|z_{1:t-1}, u_{1:t})
\tag{23}
$$
因此：
$$
bel(x_t) = \eta p(z_t | x_t) \overline{bel}(x_t) \tag{24}
$$
利用全概率公式对$\overline{bel}(x_t)$进行变换：
$$
\overline{bel}(x_t) = p(x_t|z_{1:t-1}, u_{1:t})=\int p(x_t|z_{1:t-1}, u_{1:t}, x_{t-1}) p(x_{t-1}|z_{1:t-1},u_{1:t}) dx_{t-1} \tag{25}
$$
根据完整性这个假设，如果知道$x_{t-1}$，那么过去的测量和控制不会传递任何关于$x_t$的信息。所以可以对(25)式进行进一步的化简：
$$
\overline{bel}(x_t) = p(x_t|z_{1:t-1}, u_{1:t})=\int p(x_t|x_{t-1},  u_{t}) p(x_{t-1}|z_{1:t-1},u_{1:t}) dx_{t-1} \tag{26}
$$

> 总之，贝叶斯滤波算法以到时间$t$的测量和控制数据为条件来计算状态$x_t$的后验。推导假设世界是马尔科夫的，也就是状态是完整的。

**Bayes filter algorithm**

------

Bayes_filter_algorithm( bel($x_{t-1}), u_{t}, z_t$ ): 

- for all $x_t$ do
  - $\overline{bel}(x_t) = \int p(x_t | u_t, x_{t-1}) bel(x_{t-1})dx_{t-1}$
  - $bel(x_t) = \eta p(z_t | x_t) \overline{bel}(x_t)$
- endfor
- return $bel(x_t)$

------





















































